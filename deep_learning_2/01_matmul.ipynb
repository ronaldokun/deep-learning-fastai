{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Matrix multiplication from foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## Multiplicação de matrizes somente com o fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The *foundations* we'll assume throughout this course are:\n",
    "\n",
    "- Python\n",
    "- Python modules (non-DL)\n",
    "- pytorch indexable tensor, and tensor creation (including RNGs)\n",
    "- fastai.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Os *fundamentos* que assumimos ao longo deste curso são:\n",
    "\n",
    "- Python\n",
    "- módulos Python (Exceto DL)\n",
    "- tensor indexável do pytorch e criação de tensores (incluindo Gerador de Números Pseudo-Aleatórios)\n",
    "- fastai.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Check imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_00 import *\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run tests in console:\n",
    "# ! python run_notebook.py 01_matmul.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/clouderizer/fastai-1.0/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "n,c = x_train.shape\n",
    "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_train.shape[0]==y_train.shape[0]==50000\n",
    "test_eq(x_train.shape[1],28*28)\n",
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view(28,28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD9hJREFUeJzt3XuMVGWax/FvN4asEBVxssKwYwju\n5HG12pBh1cF4gVWGwegqlwkhXogSmWxkYrIZE0f9Q0hwzCC6QdgJk9n1toHgLQM4o4KA8ocJKyqm\ne5g8O04mJkJPUIaWm6JA7R9d3dNV9Hmr6vSpqgPv75N0rHOeOqceq/tHnXPeqnrbisUiInJma291\nAyLSeAq6SAQUdJEIKOgiEVDQRWJQLBYb/gMUB/50dnYWK9fl5Ue9qbfTta9QBtvSDq+Z2VPA90sP\ncr+7v5d037a2trIHKRaLtLW1pXrcRlNv6ai3+mXdV7FYTNxZqkN3M7se+K67TwYWACtS9iYiTZD2\nHP0G4DcA7v4H4HwzOzezrkQkU2el3G4M8P6A5c9K6w4OdufOzk4KhULZujy/I0+9paPe6tesvtIG\nvVLwRKOjo6NsOa/nTKDe0lJv9WvAOXpiLe2h+156X8H7fBvoTrkvEWmwtEHfBMwBMLPvAXvd/VBm\nXYlIplIF3d3fBd43s3fpveJ+X6ZdiUimUo+j1/UgGkfPhHpLJ6+95X4cXUROLwq6SAQUdJEIKOgi\nEVDQRSKgoItEQEEXiYCCLhIBBV0kAgq6SAQUdJEIKOgiEVDQRSKgoItEQEEXiYCCLhIBBV0kAgq6\nSAQUdJEIKOgiEVDQRSKgoItEQEEXiYCCLhIBBV0kAgq6SAQUdJEIKOgiEVDQRSJwVqsbkMYYNmxY\nsH7eeedl/pijR4/uv71o0aLE+40YMSK4HzML1u+7LzxL9xNPPHHKujVr1gAwb9684LZfffVVsP74\n448H64sXLw7WWyVV0M1sCvAS8PvSqk53/0lWTYlItobyiv6Ou8/JrBMRaRido4tEoK1YLNa9UenQ\n/T+Bj4HRwGJ335x0/66urmKhUEjbo4jUpi2xkDLo44BrgBeBCcA24B/d/etBH6StrexBisUibW2J\nPbXUmdJbsy/G7d+/nwsuuKB/OU8X4+bNm8fatWv7b4c082Jc1n9rxWIxcWepztHdfQ+wrrT4JzP7\nCzAO+HOa/YlIY6U6Rzez283sp6XbY4ALgT1ZNiYi2Ul71X0DsMbMbgWGA/+WdNges4suuihYHz58\neLB+9dVXn7Lurrvu6r99zTXXJG47atSo4L5nz54drKfx2WefZbKfTz/9NFhfsWJFsD5z5sxT1s2d\nOxeAQ4cOBbf96KOPgvV33nknWM+rtIfuh4BbMu5FRBpEw2siEVDQRSKgoItEQEEXiYCCLhKBVO+M\nq/tBztB3xk2cODFY37p1a7Be77vT2tvbOXnyZF3bNEs9vVW73z333BOsHz58uOa+AF599VVmzZoF\nQHd3d/C+Bw4cCNbdva7HDmnmO+P0ii4SAQVdJAIKukgEFHSRCCjoIhFQ0EUioKCLREDj6BXq6W3g\n1xsPZseOHcH6hAkTau4LmjuOXq33np6esuUZM2bw+uuv9y9PnTo1cduvvw5/ojnrb7/J69+bxtFF\nJFMKukgEFHSRCCjoIhFQ0EUioKCLREBBF4mAxtErZNnbbbfdFqzffPPNwfqHH35Ytrxy5cqyGVCq\nfe1xyK5du4L16667Llg/cuRI2XLl83bZZZclbnv//fcH971w4cJgvV55/XvTOLqIZEpBF4mAgi4S\nAQVdJAIKukgEFHSRCCjoIhHQOHqFZvZ27rnnBuuVU/yePHmS9va//du8evXqxG0XLFgQ3Pcdd9wR\nrK9duzZYr6Tfaf2aOY5e07TJZlYA1gNPuftKM/sO8AIwDOgG7nT3Y1k0KyLZq3robmYjgaeBLQNW\nLwFWufu1wMdAeGoNEWmpWs7RjwE3AXsHrJsCbCjd3gjcmG1bIpKlqofu7n4cOG5mA1ePHHCovg8Y\nG9pHZ2cnhUKhbF0zrg2klefesvrOuDVr1gypPpg8P2957a1ZfdV0jl5F1asJHR0dZct5vTgCuhjX\nRxfjGq8BF+MSa2mH1w6b2dml2+MoP6wXkZxJG/S3gNml27OBN7JpR0Qaoeqhu5lNApYD44FvzGwO\ncDvwrJn9GPgEeK6RTZ6pDh48WPc2Aw/Pvvjii9SPfe+99wbr69atC9bzOk+7DK6Wi3Hv03uVvdK0\nzLsRkYbQW2BFIqCgi0RAQReJgIIuEgEFXSQC+phqhdOpt5EjRybed+PGjcF9XX/99cH6jBkzgvVN\nmzYFe8uTvPamr3sWkUwp6CIRUNBFIqCgi0RAQReJgIIuEgEFXSQCGkevcKb0dvHFFwfrH3zwQbDe\n09MTrG/btq1sef78+Tz33N8+rbxz587EbVetWhXcd9Z/k3n9nWocXUQypaCLREBBF4mAgi4SAQVd\nJAIKukgEFHSRCGgcvUIsvc2cOTNYf+aZZ4L1c845p2y5vb295q+Afuihh4L1559/Pljv7u6u6XH6\n5PV3qnF0EcmUgi4SAQVdJAIKukgEFHSRCCjoIhFQ0EUioHH0CuqtV6FQCNaffPLJsuVp06axefPm\n/uUbbrgh9WOvXr06WF+6dGmwvmfPnrLlvP5OmzmOXnXaZAAzKwDrgafcfaWZPQtMAvaX7rLM3X87\n1EZFpDGqBt3MRgJPA1sqSj9z99ca0pWIZKqWc/RjwE3A3gb3IiINUvM5upk9Cnw+4NB9DDAc2Acs\ncvfPk7bt6uoqVjvnE5EhG9o5+iBeAPa7+y4zexB4FFiUdOeOjo6y5bxeHAH11kcX4xqvARfjEmup\ngu7uA8/XNwC/TLMfEWmOVOPoZvaKmU0oLU4BujLrSEQyV/Uc3cwmAcuB8cA3wB56r8I/CBwFDgN3\nu/u+xAfROHom8tTbqFGjypYPHDjA+eef3798yy23JG5b7bPu1f4ft27dGqxPmzatbDlPz9tAuRpH\nd/f36X3VrvTKEHoSkSbSW2BFIqCgi0RAQReJgIIuEgEFXSQC+phqBfWWTj29HTt2LFg/66zwYNDx\n48eD9enTp5ctb9u2jalTpwLw9ttvV2+wSfR1zyKSKQVdJAIKukgEFHSRCCjoIhFQ0EUioKCLRCDt\nN8zIGe7yyy8P1ufMmXPKuiVLlvTfvuKKKxK3rTZOXs3u3buD9e3bt9e0LiZ6RReJgIIuEgEFXSQC\nCrpIBBR0kQgo6CIRUNBFIqBx9DOUmQXrixYlTqwDwKxZs4L1MWPGnLLu4Ycfrt5YDU6cOBGsd3d3\nB+snT56saV1M9IouEgEFXSQCCrpIBBR0kQgo6CIRUNBFIqCgi0RA4+g5NthY9cB18+bNS9y22jj5\n+PHjU/c1VDt37gzWly5dGqxv2LAhy3aiUFPQzewXwLWl+/8ceA94ARgGdAN3unv4W/lFpGWqHrqb\n2VSg4O6TgR8C/wEsAVa5+7XAx8A9De1SRIaklnP07cCPSrd7gJHAFKDv+GkjcGPmnYlIZuqae83M\nFtJ7CD/d3f++tO5i4AV3vzppu66urmKhUBhqryISljj3Ws0X48zsVmAB8APgj7XsvE9HR0fZ8pky\nWWCjVV6M6+7uZuzYsf3LeboY197eXvMHR5p9MS5Pv9OBGjDJYmKtpuE1M5sOPAzMcPcvgMNmdnap\nPA7YO9QmRaRxqr6im9l5wDLgRnf/a2n1W8Bs4H9K/32jYR2exi688MJg/dJLLw3WV65cecq6LVu2\n9N++5JJL0jWWgR07dpQtT548uWzdsmXLErddv359cN+xf6S0EWo5dJ8LfAt4ccBnnOcDvzazHwOf\nAM81pj0RyULVoLv7r4BfDVKaln07ItIIegusSAQUdJEIKOgiEVDQRSKgoItEoK63wKZ+kLa2sgfJ\n6zuV4NTeRo8enXjf1atXB/c1ceLEYH3ChAl19VbPu8+qeffdd4P15cuXB+tvvvlm2fLRo0cZMWJE\n//KXX36ZvrmM5fXvrQHvjEvcmV7RRSKgoItEQEEXiYCCLhIBBV0kAgq6SAQUdJEInPFf93zVVVcF\n6w888MAp615++eX+21deeWXituPGjUvfWAaOHj2aWFuxYkVw28ceeyxYP3LkSN395GnsXMrpFV0k\nAgq6SAQUdJEIKOgiEVDQRSKgoItEQEEXicAZP44+c+bMuuvVtqnV7t27g/XXXnstWD9+/HjZ8iOP\nPFI2/h36zHhPT08NHUos9IouEgEFXSQCCrpIBBR0kQgo6CIRUNBFIqCgi0Sgpu91N7NfANfSO+7+\nc+BfgUnA/tJdlrn7bxMf5DT+Xvc8UW/p5LW3Zn6ve9U3zJjZVKDg7pPN7ALgQ2Ar8DN3D7/jQ0Ry\noZZ3xm0H/rd0uwcYCQxrWEcikrm6pmQys4X0HsKfAMYAw4F9wCJ3/zxpu66urmKhUBhiqyJSReKh\ne81BN7NbgYeAHwD/DOx3911m9iDwD+6+KPFBdI6eCfWWTl57y9U5OoCZTQceBn7o7l8AWwaUNwC/\nHFKHItJQVYfXzOw8YBlws7v/tbTuFTPrmwp0CtDVsA5FZMhqeUWfC3wLeNHM+tY9A6wzs6PAYeDu\nxrQnIlnQ/OgV1Fs66q1+mh9dRDKloItEQEEXiYCCLhIBBV0kAgq6SAQUdJEIKOgiEVDQRSKgoItE\nQEEXiYCCLhIBBV0kAgq6SASa8jFVEWktvaKLREBBF4mAgi4SAQVdJAIKukgEFHSRCCjoIhGoaaaW\nLJnZU8D3gSJwv7u/1+weBmNmU4CXgN+XVnW6+09a1xGYWQFYDzzl7ivN7DvAC/ROctkN3Onux3LS\n27PUMZV2g3urnOb7PXLwvA11+vGhaGrQzex64LulKZj/CfhvYHIze6jiHXef0+omAMxsJPA05dNf\nLQFWuftLZvYYcA8tmA4roTfIwVTaCdN8b6HFz1urpx9v9qH7DcBvANz9D8D5ZnZuk3s4XRwDbgL2\nDlg3hd657gA2Ajc2uac+g/WWF9uBH5Vu903zPYXWP2+D9dW06cebfeg+Bnh/wPJnpXUHm9xHkkvN\nbAMwGljs7ptb1Yi7HweOD5gGC2DkgEPOfcDYpjdGYm8Ai8zs36lhKu0G9nYCOFJaXAD8Dpje6uct\noa8TNOk5a/XFuDzNk/NHYDFwKzAf+C8zG97aloLy9NxB7znwg+7+L8Au4NFWNlOa5nsBUDmdd0uf\nt4q+mvacNfsVfS+9r+B9vk3vxZGWc/c9wLrS4p/M7C/AOODPrevqFIfN7Gx3/5Le3nJz6OzuuZlK\nu3KabzPLxfPWyunHm/2KvgmYA2Bm3wP2uvuhJvcwKDO73cx+Wro9BrgQ2NPark7xFjC7dHs28EYL\neymTl6m0B5vmmxw8b62efrzpH1M1s8eB64CTwH3u/lFTG0hgZucAa4BRwHB6z9F/18J+JgHLgfHA\nN/T+o3M78Czwd8AnwN3u/k1OensaeBDon0rb3fe1oLeF9B4C/9+A1fOBX9PC5y2hr2foPYRv+HOm\nz6OLRKDVF+NEpAkUdJEIKOgiEVDQRSKgoItEQEEXiYCCLhKB/wcGHQ6X7PrItwAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10)/math.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape # n_rows * n_cols\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac): # or br\n",
    "                c[i,j] += a[i,k] * b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_valid[:5]\n",
    "m2 = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 628 ms, sys: 1.39 ms, total: 629 ms\n",
      "Wall time: 635 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators (+,-,\\*,/,>,<,==) are usually element-wise.\n",
    "\n",
    "Examples of element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14.,  3.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Frobenius norm:\n",
    "\n",
    "$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$\n",
    "\n",
    "*Hint*: you don't normally need to write equations in LaTeX yourself, instead, you can click 'edit' in Wikipedia and copy the LaTeX from there (which is what I did for the above equation). Or on arxiv.org, click \"Download: Other formats\" in the top right, then \"Download source\"; rename the downloaded file to end in `.tgz` if it doesn't already, and you should find the source there, including the equations to copy and paste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "Norma Frobenius:\n",
    "\n",
    "$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$\n",
    "\n",
    "*Sugestão*: você não precisa escrever equações no LaTeX, você pode clicar em 'editar' na Wikipedia e copiar o LaTeX de lá (o que eu fiz para a equação acima). Ou em arxiv.org, clique em \"Download: Outros formatos\" no canto superior direito, depois em \"Baixar fonte\"; renomeie o arquivo baixado para terminar em `.tgz` se ele ainda não existir, e você deve encontrar a fonte lá, incluindo as equações para copiar e colar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Elementwise matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "pt"
   },
   "source": [
    "#### Elementwise matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            # Any trailing \",:\" can be removed\n",
    "            c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 1.19 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a,b): test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **broadcasting** describes how arrays with different shapes are treated during arithmetic operations.  The term broadcasting was first used by Numpy.\n",
    "\n",
    "From the [Numpy Documentation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):\n",
    "\n",
    "    The term broadcasting describes how numpy treats arrays with \n",
    "    different shapes during arithmetic operations. Subject to certain \n",
    "    constraints, the smaller array is “broadcast” across the larger \n",
    "    array so that they have compatible shapes. Broadcasting provides a \n",
    "    means of vectorizing array operations so that looping occurs in C\n",
    "    instead of Python. It does this without making needless copies of \n",
    "    data and usually leads to efficient algorithm implementations.\n",
    "    \n",
    "In addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\n",
    "\n",
    "*This section was adapted from [Chapter 4](http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#4.-Compressed-Sensing-of-CT-Scans-with-Robust-Regression) of the fast.ai [Computational Linear Algebra](https://github.com/fastai/numerical-linear-algebra) course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting with a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6., -4.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we able to do a > 0?  0 is being **broadcast** to have the same dimensions as a.\n",
    "\n",
    "Remember above when we normalized our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar)?  We were using broadcasting!\n",
    "\n",
    "Other examples of broadcasting with a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.,  7., -3.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.],\n",
       "        [14., 16., 18.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting a vector to a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also broadcast a vector to a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape,c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really copy the rows, but it looks as if we did. In fact, the rows are given a *stride* of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c.expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index with the special value [None] or use `unsqueeze()` to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "pt",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
